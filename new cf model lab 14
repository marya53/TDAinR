#построение модели CF заново по лабе 14 и оценивание


```{r message = FALSE}
library(tidyverse)
library(recommenderlab)
library(readr)
library(tidyr)
```

Чтение данных

```{r}
load("~/shared/minor2_2023/data/project/ratings_g_7.RData")
ratings = ratings %>% rename(movieId = item_id,userId = user_id)
```


Преобразуем к таблице в "широком" формате

```{r}
rates = pivot_wider(ratings, names_from = movieId, values_from = rating)
```

Оставляем только оценки, поэтому переведем пользователей в имена строк. Преобразуем к нужному формату и уберем фильмы и пользователей с небольшим числом оценок

```{r}
userNames = rates$userId
rates = select(rates, -userId)
rates = as.matrix(rates)
rownames(rates) = userNames
r = as(rates, "realRatingMatrix")
ratings_movies <- r[rowCounts(r) > 20, colCounts(r) > 15] 
ratings_movies_2 <- r[rowCounts(r) > 15, colCounts(r) > 10] 
```

#Строим модель и предсказание. До этого мы делили на тестовую и обучающую выборки сами, отбирая каких-то пользователей в обучающую выборку (т.е. используя их историю оценок для формирования "коллективной" рекомендации), а каких-то в тестовую (данные которых мы использовали только для того, чтобы сформировать рекомендацию только этому же пользователю).

#Сейчас же мы хотим поделить оценки и "внутри" каждого пользователя, часть из которых использовать, как и раньше, для формирования рекомендаций, а часть "забыть", т.е. считать, что мы их не знаем, и потом сравнить рекомендацию с реальностью. Например, пусть пользователь оценил 25 фильмов. Мы "забываем" оценки 15 из них, на основе оставшихся 10 строим предсказание, а потом сравниваем исходные оценки первых 15 с теми значениями, что мы предсказали.

#Это можно сделать и вручную, но пакет `recommenderlab` предлагает нам "схемы", которые сделают то же самое.

#При этом мы можем указать, какие оценки нас устраивают, т.е. в каком случае мы действительно хотим рекомендовать что-то пользователю. Рассмотрим вариант, когда подходят 4 и 5 (параметр goodRating).

#Параметр given показывает, сколько оценок пользователя мы будем использовать для сравнения -- в примере выше это те 10 фильмов, которые мы не "забыли" (т.е. у всех пользователей должно быть не меньше given оцененных фильмов -- вспомним проблему со смещенными рекомендациями, когда оценок мало). Чтобы это условие выполнялось мы и удалили пользователей с менее 15 оценками (см. сроку 44)

```{r}
set.seed(100)
# ?evaluationScheme
eval_sets <- evaluationScheme(data = ratings_movies, 
                              method = "split",
                              train = 0.8, # доля обучающей выборки
                              given = 15, # сколько оценок используется для  предсказания
                              goodRating = 4) # если предсказанная оценка < 4, то фильм не рекомендуем
```


#Строим модель на обучающей, предсказываем на тестовой

```{r}
recc_model_14 <-
  Recommender(data = getData(eval_sets, "train"), method = "IBCF")

recc_predicted <-
  predict(
    object = recc_model,
    newdata = getData(eval_sets, "known"),
    n = 6,
    type = "ratings"
  )
str(recc_predicted)
```

#Мы сделали предсказание, давайте посмотрим на его качество. Качество = отклонение предсказания от реальности. Для этого у нас есть unknown оценки -- они не используются для предсказания для этого пользователя, но это те фильмы, для которых мы знаем "реальные" оценки, т.е. можем сравнить, насколько наше предсказание оказалось похожим на правду.

```{r}
?calcPredictionAccuracy

eval_accuracy <- calcPredictionAccuracy(
      x = recc_predicted,
      data = getData(eval_sets, "unknown"),
      byUser = T# averaging for each user
)

head(eval_accuracy)
```
#Эта таблица дает результат по ошибкам, усредненный для каждого пользователя (например, если у пользователя 35 оценок, мы использовали 15 для описания его предпочтений, а для оставшихся 20 делаем предсказание. Ошибка как раз усредняется по этим 20 оценкам).

#Например, можно обобщить значения в визуализации

```{r}
eval_accuracy %>% 
  as_tibble() %>% 
  ggplot(aes(x = RMSE, y = 1))+
  geom_violin()+
  geom_boxplot()
```

#Вариант ниже -- усредненный на всех пользователей

```{r}
eval_accuracy2 <- calcPredictionAccuracy(
      x = recc_predicted,# predicted values
      data = getData(eval_sets, "unknown"),
      byUser = F) # not averaging for each user

eval_accuracy2
```

#положила эту модель в функцию, которую до этого написал Феликс

```{r}
get_recommendations_14 <- function(user_ratings) {
   # user_ratings - это вектор оценок фильмов, поставленных пользователем, где имена элементов - это ID фильмов.

user_ratings_matrix <- as(user_ratings, "realRatingMatrix")
recommendations <- predict(object = recc_model_14, newdata = user_ratings_matrix, n = 6)
recommended_items <- as(recommendations, "list")
   return(recommended_items[[1]])
}
```
